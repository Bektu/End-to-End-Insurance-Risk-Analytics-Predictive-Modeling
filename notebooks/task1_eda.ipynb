{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70771252",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Correct load using pipe delimiter\u001b[39;00m\n\u001b[32m     12\u001b[39m df = load_data(\u001b[33m\"\u001b[39m\u001b[33m../data/raw/MachineLearningRating_v3.txt\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotalClaims\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mpd\u001b[49m.to_numeric(df[\u001b[33m'\u001b[39m\u001b[33mTotalClaims\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotalPremium\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df[\u001b[33m'\u001b[39m\u001b[33mTotalPremium\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Shape:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvisualizations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_histogram, plot_boxplot, plot_loss_ratio_by_category\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Correct load using pipe delimiter\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../data/raw/MachineLearningRating_v3.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m|\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotalClaims\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df[\u001b[33m'\u001b[39m\u001b[33mTotalClaims\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mTotalPremium\u001b[39m\u001b[33m'\u001b[39m] = pd.to_numeric(df[\u001b[33m'\u001b[39m\u001b[33mTotalPremium\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\src\\data_loader.py:6\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(filepath, sep, encoding)\u001b[39m\n\u001b[32m      3\u001b[39m def load_data(filepath: str, sep: str = \"|\") -> pd.DataFrame:\n\u001b[32m      4\u001b[39m     df = pd.read_csv(filepath, sep=sep)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     # Convert key numeric fields\n\u001b[32m      7\u001b[39m     numeric_fields = ['TotalClaims', 'TotalPremium', 'CustomValueEstimate']\n\u001b[32m      8\u001b[39m     for col in numeric_fields:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:252\u001b[39m, in \u001b[36mPythonParser.read\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\n\u001b[32m    247\u001b[39m     \u001b[38;5;28mself\u001b[39m, rows: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    248\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\n\u001b[32m    249\u001b[39m     Index | \u001b[38;5;28;01mNone\u001b[39;00m, Sequence[Hashable] | MultiIndex, Mapping[Hashable, ArrayLike]\n\u001b[32m    250\u001b[39m ]:\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         content = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    254\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._first_chunk:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\KAIM\\End-to-End-Insurance-Risk-Analytics-Predictive-Modeling\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1139\u001b[39m, in \u001b[36mPythonParser._get_lines\u001b[39m\u001b[34m(self, rows)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     rows = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         next_row = \u001b[38;5;28mself\u001b[39m._next_iter_line(row_num=\u001b[38;5;28mself\u001b[39m.pos + rows + \u001b[32m1\u001b[39m)\n\u001b[32m   1141\u001b[39m         rows += \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "#src_path=os.path.abspath('../src')\n",
    "#sys.path.append(src_path)\n",
    "\n",
    "from src.data_loader import load_data, parse_dates\n",
    "from src.eda import compute_loss_ratio, group_loss_ratio, check_missing, get_summary_stats\n",
    "from src.visualizations import plot_histogram, plot_boxplot, plot_loss_ratio_by_category\n",
    "# Correct load using pipe delimiter\n",
    "df = load_data(\"../data/raw/MachineLearningRating_v3.txt\", sep=\"|\", encoding=\"utf-8\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d88b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shape: (1000098, 52)\n",
      "‚úÖ First 5 columns: ['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth', 'IsVATRegistered', 'Citizenship']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df['TotalClaims'] = pd.to_numeric(df['TotalClaims'], errors='coerce')\n",
    "df['TotalPremium'] = pd.to_numeric(df['TotalPremium'], errors='coerce')\n",
    "print(\"‚úÖ Shape:\", df.shape)\n",
    "print(\"‚úÖ First 5 columns:\", df.columns.tolist()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d3428f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2015-03-01\n",
      "1   2015-05-01\n",
      "2   2015-07-01\n",
      "3   2015-05-01\n",
      "4   2015-07-01\n",
      "Name: TransactionMonth, dtype: datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"\")\n",
    "\n",
    "# ‚úÖ Now parse the date\n",
    "df = parse_dates(df, date_column=\"TransactionMonth\")\n",
    "\n",
    "# Confirm\n",
    "print(df[\"TransactionMonth\"].head())\n",
    "print(df[\"TransactionMonth\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e66ac022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " NumberOfVehiclesInFleet     1000098\n",
      "CrossBorder                  999400\n",
      "CustomValueEstimate          779642\n",
      "Rebuilt                      641901\n",
      "Converted                    641901\n",
      "WrittenOff                   641901\n",
      "NewVehicle                   153295\n",
      "Bank                         145961\n",
      "AccountType                   40232\n",
      "Gender                         9536\n",
      "MaritalStatus                  8259\n",
      "NumberOfDoors                   552\n",
      "VehicleType                     552\n",
      "kilowatts                       552\n",
      "cubiccapacity                   552\n",
      "Cylinders                       552\n",
      "Model                           552\n",
      "make                            552\n",
      "VehicleIntroDate                552\n",
      "bodytype                        552\n",
      "mmcode                          552\n",
      "CapitalOutstanding                2\n",
      "TermFrequency                     0\n",
      "CalculatedPremiumPerTerm          0\n",
      "ExcessSelected                    0\n",
      "CoverCategory                     0\n",
      "CoverType                         0\n",
      "CoverGroup                        0\n",
      "Section                           0\n",
      "Product                           0\n",
      "StatutoryClass                    0\n",
      "StatutoryRiskType                 0\n",
      "TotalPremium                      0\n",
      "SumInsured                        0\n",
      "UnderwrittenCoverID               0\n",
      "TrackingDevice                    0\n",
      "Country                           0\n",
      "TransactionMonth                  0\n",
      "IsVATRegistered                   0\n",
      "Citizenship                       0\n",
      "LegalType                         0\n",
      "Title                             0\n",
      "Language                          0\n",
      "Province                          0\n",
      "AlarmImmobiliser                  0\n",
      "PostalCode                        0\n",
      "MainCrestaZone                    0\n",
      "SubCrestaZone                     0\n",
      "ItemType                          0\n",
      "RegistrationYear                  0\n",
      "PolicyID                          0\n",
      "TotalClaims                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Quality Checks\n",
    "missing = check_missing(df)\n",
    "print(\"Missing values:\\n\", missing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18c48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderwrittenCoverID\n",
      "PolicyID\n",
      "TransactionMonth\n",
      "IsVATRegistered\n",
      "Citizenship\n",
      "LegalType\n",
      "Title\n",
      "Language\n",
      "Bank\n",
      "AccountType\n",
      "MaritalStatus\n",
      "Gender\n",
      "Country\n",
      "Province\n",
      "PostalCode\n",
      "MainCrestaZone\n",
      "SubCrestaZone\n",
      "ItemType\n",
      "mmcode\n",
      "VehicleType\n",
      "RegistrationYear\n",
      "make\n",
      "Model\n",
      "Cylinders\n",
      "cubiccapacity\n",
      "kilowatts\n",
      "bodytype\n",
      "NumberOfDoors\n",
      "VehicleIntroDate\n",
      "CustomValueEstimate\n",
      "AlarmImmobiliser\n",
      "TrackingDevice\n",
      "CapitalOutstanding\n",
      "NewVehicle\n",
      "WrittenOff\n",
      "Rebuilt\n",
      "Converted\n",
      "CrossBorder\n",
      "NumberOfVehiclesInFleet\n",
      "SumInsured\n",
      "TermFrequency\n",
      "CalculatedPremiumPerTerm\n",
      "ExcessSelected\n",
      "CoverCategory\n",
      "CoverType\n",
      "CoverGroup\n",
      "Section\n",
      "Product\n",
      "StatutoryClass\n",
      "StatutoryRiskType\n",
      "TotalPremium\n",
      "TotalClaims\n"
     ]
    }
   ],
   "source": [
    "# Clean column names\n",
    "df.columns = df.columns.str.strip()               # Remove leading/trailing whitespace\n",
    "df.columns = df.columns.str.replace(\" \", \"\")      # Remove internal spaces (optional)\n",
    "#df.columns = df.columns.str.lower()               # Convert to lowercase\n",
    "for col in df.columns:\n",
    "    print(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d70c3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Stats:\n",
      "        TotalPremium   TotalClaims  CustomValueEstimate\n",
      "count  1.000098e+06  1.000098e+06         2.204560e+05\n",
      "mean   6.190550e+01  6.486119e+01         2.255311e+05\n",
      "std    2.302845e+02  2.384075e+03         5.645157e+05\n",
      "min   -7.825768e+02 -1.200241e+04         2.000000e+04\n",
      "25%    0.000000e+00  0.000000e+00         1.350000e+05\n",
      "50%    2.178333e+00  0.000000e+00         2.200000e+05\n",
      "75%    2.192982e+01  0.000000e+00         2.800000e+05\n",
      "max    6.528260e+04  3.930921e+05         2.655000e+07\n"
     ]
    }
   ],
   "source": [
    "# --- Summary Stats for Financial Columns ---\n",
    "key_numeric = ['TotalPremium', 'TotalClaims', 'CustomValueEstimate']\n",
    "summary_stats = get_summary_stats(df, key_numeric)\n",
    "print(\"\\nSummary Stats:\\n\", summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c69076be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TotalClaims     float64\n",
      "TotalPremium    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[['TotalClaims', 'TotalPremium']].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe116ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Portfolio Loss Ratio: 1.0477452570332202\n"
     ]
    }
   ],
   "source": [
    "from src.eda import compute_loss_ratio, group_loss_ratio\n",
    "#df.columns = df.columns.str.lowerc()\n",
    "\n",
    "print(\"üìä Portfolio Loss Ratio:\", compute_loss_ratio(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241e3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.visualizations import plot_histogram, plot_boxplot, plot_loss_ratio_by_category\n",
    "\n",
    "# Plot numeric distributions\n",
    "for col in ['TotalPremium', 'TotalClaims', 'CustomValueEstimate']:\n",
    "    plot_histogram(df, col)\n",
    "    plot_boxplot(df, col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c297aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eda import group_loss_ratio\n",
    "\n",
    "for cat in ['province', 'vehicletype', 'gender']:\n",
    "    if cat in df.columns:\n",
    "        grouped = group_loss_ratio(df, cat)\n",
    "        print(f\"\\nüìç Loss Ratio by {cat}:\")\n",
    "        print(grouped.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9de3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
